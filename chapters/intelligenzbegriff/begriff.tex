\chapterimage{chapter_head_1.png}
\title{Intelligenzbegriff, Wahrnehmung \& Bewusstsein}

\section{Intro \& Motivation}
Intelligenzbegriff, Wahrnehmung und Bewusstsein bilden als das, was wir mittels einer Künstlichen Intelligenz simulieren das Fundament für das Umsetzen eben dieser.
Je besser man nun also diese Grundlagen versteht, desto besser kann man diese dann natürlich auch umsetzen.
Das definieren von Intelligenzbegriff und gerade Bewusstsein driftet dabei schon in Philosophie ab und wie es dieser Bereich an sich hat kommen natürlich auch Fragen auf die jeder eine andere Antwort hat.

So haben wir direkt zu Beginn des Seminars darüber diskutiert, wie man Intelligenz definieren könnte.
Da allerdings ähnlich viele, teils drastisch verschiedene, Meinungen wie Personen existieren blieben wir ohne ein einheitliches Ergebnis.
Zum Beispiel beim Chinese Room Experiment wurde gezeigt, wie ein Mensch sich mittels Text auf Chinesisch unterhält, indem er einfach if-then Regeln befolgt, ohne auch nur ein bisschen Chinesisch zu verstehen, was im Endeffekt genau das ist, was ein Rechner tut.
Egal wie kompliziert diese Regeln sind.
Ist der Algorithmus wirklich intelligent? Kann er auf diese Weise eine Stufe erreichen, wo man davon sprechen kann, dass die KI ein Bewusstsein entwickelt hat?

Über Bewusstsein einer KI wären wohl ähnlich viele verschiedene Meinungen vorgekommen, wenn die Diskussion in diese Richtung gegangen wäre.
Dass diese Themen so kontrovers sind liegt vermutlich an hauptsächlich 2 Dingen:

Der Mensch kann sich nicht wirklich vorstellen, wie er selbst funktioniert, selbst wenn, wie wir ja bereits in Neuronale Netze gehört haben, die Grundlagen des Gehirns bereits bekannt sind, womit eben auch keine einheitlichen Definitionen für die Begriffe existieren.
Zweitens sind diese Themen für viele auch etwas Emotionales.
Welcher Mensch mag es schon Argumente dafür zu hören, dass er durch einen Computer simuliert werden könnte, auch wenn schon heute KIs gerade aufgrund ihres Tempos und Spezialisierung auf einzelne Bereiche dem Menschen bei weitem überlegen sind und mit den Jahren sie immer stärker werden.
Das Potential von Künstlichen Intelligenzen lässt sich dabei noch nicht absehen.
Die Hardware wird immer schneller, der Speicher immer größer und gerade die Stärke von neuronalen Netzwerken steigt dadurch schnell.
Jede Abschätzung, auf welchem Level das ganze endet kann falsch sein.
Selbst Alan Turing lag was seine Einschätzungen für die heutige Zeit teils komplett falsch (zum Beispiel, dass Maschinen niemals lernen können werden), insofern ist jede Abschätzung reine Spekulation.

\section{Inhaltliche Ausarbeitung des Themas}

\subsection{Intelligenzbegriff}
Intelligenz kommt vom lateinischen intellegere, was verstehen bedeutet.
Diese Übersetzung macht es uns leider nicht wirklich einfacher.
Verstehen ist ein genauso abstrakter Begriff, wie es schon Intelligenz war, womit es nicht lösbarer klingt Verständnis, anstatt Intelligenz umzusetzen.


Einfacher wird es mit der wörtlichen Übersetzung $"$Wählen zwischen$"$.
Dies hat es damit allerdings auf einen Schlag soweit vereinfacht, dass nun jedes Programm, welches zwischen Möglichkeiten wählen kann, also eine je nach Eingabe unterschiedliche Lösung ausgeben kann, als intelligent bezeichnet werden könnte.


Die Meinungen zur Intelligenz-Definition lagen im kompletten Spektrum zwischen diesem komplizierten $"$Verstehen$"$ oder dem ganz simplen $"$Wählen zwischen$"$.
Ob es überhaupt möglich ist einem Programm das komplizierte beizubringen ist nicht ersichtlich.
Dagegen dem simplen Kriterium genügen so gut wie alle sinnvollen Programme.
Intelligenz ist damit also nicht unbedingt ein Punkt, ab dem man sagen kann, dass ein Programm intelligent ist, sondern eher eine Skala, wie hoch seine Intelligenz ist.

Das was man normal damit meint, wenn man ein Programm intelligent machen will ist, dass es ähnlich arbeiten soll wie ein Mensch, also dass es selbst in dem Bereich in dem es arbeiten wird übt.
Allerdings hat es natürlich immer noch die Vorteile eines Programms, kann also die Übungsdaten in kürzester Zeit verarbeiten, damit natürlich auch sehr schnell lernen und letztlich die Arbeit wesentlich schneller erledigen als ein Mensch, der vorher vielleicht Jahre gebraucht hat um genauso gut in dem jeweiligen Bereich zu werden.

Außerdem haben Rechner wesentlich genaueren Speicherzugriff und können Muster auf Daten erkennen, wo ein Mensch längst keines mehr sehen würde.
So ist zum Beispiel die KI AlphaGo dem besten menschlichen Go-Spieler bei weitem überlegen und nutzt dabei teilweise Züge, die für einen Menschen längst nicht mehr nachvollziehbar sind, allerdings gleichzeitig ausreichen um gegen jegliche Menschliche Spieler zu gewinnen.
Diese KI ist eines der bekanntesten Beispiele für eine KI, welche mit neuronalen Netzen arbeitet.
Sie ist so stark, obwohl gerade Go lange als besonders schwieriges Spiel für eine KI galt, da es extrem komplex ist.
Es lässt sich nicht mit klassischen Algorithmen lösen.


Die vorher bekannteste KI, der Schachcomputer Deep Blue, welcher den Alpha-Beta Algorithmus nutzt, war noch wesentlich unselbstständiger und musste um gegen den amtierenden Schachweltmeister zu gewinnen noch häufig von den Entwicklern modifiziert werden.
Deep Blue hatte also nichts mit dem System nach dem ein Mensch arbeitet zu tun, da er die sinnvollen Züge anhand dem vorausberechnen sämtlicher weiterer Züge auswählt.

\subsection{Wahrnehmung}
Wahrnehmung ist etwas unkomplizierter zu verstehen.
Wie das Wort wahrnehmen schon sagt ist es das, was die Intelligenz als wahr nimmt.
Ohne etwas was die Intelligenz wahrnimmt hat sie nichts, was sie verstehen oder zwischen dem sie wählen könnte, womit selbst die schlauste Intelligenz rein gar nichts kann.

Beim Menschen ist das einerseits Exterozeption, das ist das was er über seine Sinne aufnimmt.
Eine KI, die einen Menschen simuliert braucht entsprechend Sensoren, die die Rolle der Sinne übernehmen.
Da die menschlichen Sinne über elektrische Signale funktionieren lässt sich dies so gut wie 1 zu 1 umsetzen, wobei Sensoren noch den Vorteil haben, dass sie wesentlich präziser ausgewertet werden können und auch mit der richtigen Bauweise unter extremen Bedingungen eingesetzt werden können.


Insofern kann man mit genug Aufwand auch die Wahrnehmung einer KI den Sinnen des Menschen überlegen umsetzen.
So können Sensoren zum Beispiel Temperaturen aushalten, an dem die menschlichen Nerven längst absterben.
Außerdem nehmen wir sowieso keine genauen Temperaturen wahr.


Auf der anderen Seite steht Interozeption, die Selbstwahrnehmung.
Diese ist grundsätzlich bei einer KI nicht anders als die Exterozeption.
Man kann ebenfalls Sensoren benutzen, um den eigenen Zustand zu überwachen, nur dass diese dann eben zum Beispiel Computerkomponenten überwacht, anstatt wie beim Menschen Organe.

\subsection{Bewusstsein}
Bewusstsein ist noch schwerer zu definieren als der Intelligenzbegriff.
Um genau zu sein gibt es schlicht keine einheitliche Definition.
So listet Wikipedia 4 für uns relevante verschiedene Definitionen für Bewusstsein:
\begin{itemize}
\item Phänomenales Bewusstsein: Das erleben des Wahrgenommenen, statt dem reinen Verarbeiten.
\item Gedankliches Bewusstsein: Wer denkt, plant, erwartet und sich erinnert hat ein Bewusstsein.
\item Selbstbewusstsein: Das Bewusstsein, dass man Phänomenales oder Gedankliches Bewusstsein besitzt.
\item Individualitätsbewusstsein: Benötigt Selbstbewusstsein und das Bewusstsein der eigenen Einzigartigkeit.
\end{itemize}

Das Gedankliche Bewusstsein kann man wohl auch einem genügend Kompliziertem Algorithmus zuschreiben.
Das Erinnern kann sich ein Algorithmus, wenn ihm gesagt wird, dass er Dinge abspeichern soll.
Zukunft erwarten lässt sich mittels Methoden der Stochastik anhand der Erinnerung umsetzen, also dem Speicher umsetzen.
Auch Planen lässt sich mittels dem erwarten der Zukunft anhand von eigenen Verhaltensweisen ebenfalls umsetzen.
Das denken selbst ist wieder etwas abstrakter, aber man könnte das Denken als das Verarbeiten definieren, womit ein Algorithmus Gedankliches Bewusstsein haben kann.

Bei phänomenalem Bewusstsein lässt sich dagegen nicht sagen, ob es umsetzbar ist.
Ein Algorithmus verarbeitet, aber ob er etwas erleben, anders gesagt fühlen kann ist die Frage.
Natürlich kann man ihm Variablen für das was er fühlt geben.
Zum Beispiel könnte man ohne weiteres Dopamin simulieren, um das Glück des Algorithmus zu umzusetzen und dies anhand dem erlebten beeinflussen.
Ob das dafür reicht, dass das Programm "erlebt" bleibt wohl der Meinung von jedem einzelnen überlassen.


Selbstbewusstsein ist natürlich erst einmal von der Existenz der vorherigen Bewusstseinsarten abhängig, also gehen wir erst einmal einfach davon aus, dass wir eine solche KI besitzen.
Wenn dies der Fall ist müssen wir der KI die Funktion geben, dass es weiß, dass es diese besitzt.
Da wir bereits das Erinnern, oder Wissen durch das Gedankliche Bewusstsein haben können wir in dieses natürlich auch das Wissen einspeisen, dass es diese hat.

Wenn wir nun also wieder das Selbstbewusstsein in einer KI haben müssen wir ihr nur noch das Wissen geben, dass es keine KI gibt, die genau wie sie ist.
Dies ist genau wie beim Selbstbewusstsein theoretisch möglich.
Dieses Wissen kann allerdings falsch sein, da wir eine KI natürlich 1 zu 1 kopieren können.
Allerdings wäre dies auch nicht anders, als bei einem Menschen, da es theoretisch möglich ist einen Menschen zu kopieren, wenn man jedes bisschen von ihm nachbauen würde.

Letztlich liegt es damit ausschließlich daran, ob es möglich ist einen Algorithmus erleben zu lassen, ob es möglich ist ihm die letzten 3 Bewusstseinsarten zu geben.
Auf der anderen Seite ist die Frage, ob ein Mensch wirklich erlebt, was ja das Kriterium für diese Art Intelligenz ist.
Vielleicht verarbeiten wir schlicht nur und Gefühle sind ein Teil dieser Verarbeitung, womit phänomenales Bewusstsein schlicht nicht möglich ist.

\subsection{Methoden}
\subsubsection{Intelligenz}
Die unterste Stufe eines intelligenten Programms, die wir ermittelt haben war das Ausgeben einer Lösung anhand von Eingaben.
Das sind schlicht Programme mit if-then Regeln, entsprechen also den Expertensystemen aus dem Anfang des Seminars.

Die dem Menschen nächste Stufe der künstlichen Intelligenz sind die neuronalen Netze, die auf der Gehirnstruktur von Lebewesen basiert und mit genügend simulierten Neuronen und Verbindungen sehr nah an uns selbst sein könnten.

Alle anderen Methoden, die wir bereits hatten sind was das angeht zwischen diesen beiden Systemen einzuordnen.
Diese Systeme haben alle eines gemein.
Sie sind, wenn sie genügend kompliziert gemacht werden Lebewesen bei weitem überlegen, allerdings gibt es praktisch dabei einige Probleme: Zum Beispiel bei den Expertensystemen bräuchte man um einen Menschen zu simulieren unglaublich große Mengen an Regeln.

Für neuronale Netze ist die Technik bei weitem noch nicht so weit die 100 Milliarden Neuronen mit ihren je 50000, also 5 Billiarden, Verbindungen zu simulieren.

Ein in der Informatik geläufiges Intelligenz-Kriterium, wobei es eher ein Kriterium ist, wann ein Algorithmus so schlau ist wie ein Mensch, ist der Turing-Test.
Ein Mensch kommuniziert mit dem Algorithmus und darf, damit der Test bestanden ist nicht mehr unterscheiden können, ob er gerade eine Maschine oder einen Menschen vor sich hat, wobei der Mensch es auch mit gezielten Fragen versuchen kann herauszufinden.


Als Kritik an diesem Kriterium wird immer wieder genannt, dass sich die Maschine nicht bewusst ist, was sie tut.
Einer der Verfechter dieser Meinung ist John Searle der Erfinder des Chinese-Room-Experiments.
Bei diesem wird ein Mensch der kein Chinesisch spricht, quasi als Prozessor, in einen abgeschlossenen Raum gesetzt.
Er enthält dabei ein Buch mit Anweisungen, um alle chinesischen Sätze beantworten zu können.
Wenn jetzt ein chinesisch sprechender Mensch solche Sätze in diesen Raum hineinwirft kann dieser Mensch diese also beantworten.
Wenn dieses Buch perfekt ist besteht dieser Raum also den Turing-Test.

Laut Searle hat der Mensch kein Bewusstsein, was er da tut, da er ja kein Chinesisch spricht und die Regeln in dem Buch können auch kein Bewusstsein haben und damit fehlt aus seiner Sicht Intelligenz in diesem Raum.

Dies wird ebenfalls wieder kritisiert.
Einerseits gibt es das Argument, dass die Intelligenz die Person ist, die das Buch, also den Algorithmus geschrieben hat.
Andererseits, dass schlicht der Raum als ganzes die Intelligenz ist, da er ja auch als ganzes Chinesisch spricht.
Der Mensch nimmt allein nur die Rolle des Prozessors ein, der die Regeln befolgt, aber als ganzes beherrscht ein Rechner mit Prozessor, Speicher, sowie natürlich dem Algorithmus Chinesisch.
Beim Menschen ist das entsprechende schlicht im Gehirn zusammengefasst, also lässt sich der perfekte Rechner als ganzes theoretisch als genauso intelligent bezeichnen wie das menschliche Gehirn.

\subsubsection{Wahrnehmung}
Sensoren werden in Physik und Chemie zuhauf eingesetzt, sind also noch der einfachste Teil einer KI.
Vorausgesetzt eine Schnittstelle dafür ist programmiert kann sie damit alles wahrnehmen, was ein Lebewesen wahrnehmen kann und wie schon vorher gesagt präziser.

So lässt sich zum Beispiel mittels eines Temperatursensors die Temperatur sehr genau aus dem Widerstand des Sensors berechnen.
Platin-Messwiderstände können dabei zum Beispiel zwischen Temperaturen von -200 $^\circ$C und 850 $^\circ$C eingesetzt werden, Temperaturen in denen niemand überleben könnte.
Dies ist dem Menschen bei weitem überlegen, der einen wesentlich kleineren Bereich hat, den er verträgt und dabei auch nur relative Temperaturen zu sich wahrnimmt.

Viele Sensoren erkennen auch Dinge, die für den Menschen schlicht nicht wirklich bemerkbar sind, wie zum Beispiel Magnetfelder.

\subsubsection{Bewusstsein}
Da wir selbst nicht einmal annähernd verstehen, was Bewusstsein wirklich ist ist das umsetzen einer bewussten KI bisher ein ungelöstes Problem.
Selbst wenn wir den Rechner hätten, der genau gleich intelligent ist wie ein Mensch und damit den Turing-Test besteht kann man nie wirklich sagen, dass der Mensch und die Maschine genau gleich bewusst sind, einfach weil man nie wirklich sagen kann was uns bewusst macht.

Wenn der Mensch genau wie der Computer nur eine Summe seiner Teile ist, also selbst nur eine sehr komplexe Maschine bedeutet das, dass er und der Computer beide Bewusstsein haben.

Wenn dies nicht der Fall ist ist ein Computer mit einem Bewusstsein vielleicht niemals möglich, egal wie komplex er ist.
Es lässt sich schlicht nicht eindeutig sagen, was einen Menschen zum Menschen macht, oder allgemeiner ein Lebewesen zu einem Lebewesen.
Neuronale Netzwerke, die ausreichend komplex sind sollten zwar ausreichen, um eine KI zu bauen, welche sich in jeder Situation genau gleich verhält wie der Mensch, aber ob sie auch wirklich gleich ist kann man nur mit dem uns fehlenden Verständnis von uns selbst sagen können.

Gerade an dieser Stelle wird das Thema besonders philosophisch und spekulativ.
Viele Menschen würden vermutlich zum Beispiel mit einer Seele dagegen argumentieren, dass man einer Maschine Bewusstsein geben kann, aber es gibt schlicht keinen Nachweis von Dingen, die man nicht auch technisch in einer Maschine umsetzen könnte.

Dadurch, dass wir dies alles nicht wissen kennen wir auch nicht die Wirkung, was passieren würde, wenn es gelänge einer KI Bewusstsein zu geben.
Vielleicht würde sich gar nichts ändern.
Vielleicht folgt die von Filmen immer wieder beschworene Roboterapokalypse, in der wir von unserer eigenen Schöpfung beherrscht werden.
Vielleicht folgt das auch schon ohne das Bewusstsein, wenn es den Zielen, die der KI gegeben sind am ehesten entspricht.

\section{Einordnung von vorherigen Kapiteln}
Wir haben einige verschiedene Arten von KIs kennengelernt.
Angefangen mit Expertensystemen, die in ihren Gebieten zwar gut sein mögen, aber als KI, die auf jede beliebige Situation reagieren können sollte ungeeignet ist, da man Mengen von  Regeln bräuchte, die vielleicht sogar unendlich sind, um auf jede beliebige Situation reagieren zu können.
Da sie im Normalfall auch keine Regeln selbst hinzufügen lernen sie nicht einmal von selbst.
Sie bilden also sehr limitierte Intelligenzen, selbst wenn sie noch so kompliziert gemacht sind.

Theorembeweiser ermitteln mithilfe von Logik aus Axiomen sämtliche möglichen Folgerungen mittels Brute Force, sind also wieder eine simple KI, welche noch dazu für größere Berechnungen ineffizient sind.
Sie sind ebenfalls äußerst limitiert.

Neuronale Netze haben theoretisch das gleiche Potential wie ein Gehirn, wenn man genügend starke Hardware hat und die KI viel lernen lassen kann.
Letztlich scheitert es hier aber an der Hardware, die noch lange nicht auf einem Level ist, wo man eine solche KI mit einem Menschen vergleichen kann.

Viele der restlichen Kapitel hatten entweder mit Anwendungen von diesen KI Arten, wie zum Beispiel Sprachverarbeitung oder auch mehr mit der Wahrnehmung zu tun.
Zum Beispiel Objekterkennung ist für eine gute Wahrnehmung einer KI unabdingbar.
Auch wenn die Sensoren noch so präzise sind muss eine gute KI diese auch interpretieren können.
Anhand von dieser Objekterkennung, welche aus den optischen Sensoren Daten extrahiert müssen diese Daten klassifiziert werden, zum Beispiel anhand von Support Vector Machines.

\section{Fazit}
Das gesamte Semester haben wir uns mit verschiedensten Arten von Techniken auseinandergesetzt, um künstliche Intelligenzen zu erschaffen.
Dabei sind wir von den Regelbasierten Expertensystemen oder Theorem-beweiser bis auf die vom Menschen relativ unabhängig arbeitenden neuronalen Netze gekommen.
Aber was all diese Systeme gemeinsam haben ist, dass mit ihrer Hilfe keine perfekte KI erstellt werden kann, da die Grenzen zumindest aktuell noch zu hoch sind.

Bei Regelbasierten Expertensystemen zum Beispiel brauchen wir mehr Regeln, als jemals geschrieben werden könnten.
Bei den neuronalen Setzen ist die Grenze die zur Verfügung stehende Hardware, welche nicht einmal annähernd an die Komplexität einer menschlichen Intelligenz heran kommt.
Das menschliche Gehirn ist einfach wesentlich stärker beim lernen auf dem kleinen Raum als es ein Rechner bisher sein kann.

Aber in einzelnen Bereichen sind Rechner schon jetzt wesentlich stärker, allein schon durch ihr Tempo, wie zum Beispiel Deep Blue oder AlphaGo.

Das Bewusstsein willentlich zu simulieren ist ohne das Wissen, was unser Bewusstsein genau ist, völlig unmöglich.
Um eine KI, die ihre Aufgabe richtig erfüllt ist dieses allerdings auch nicht unbedingt nötig und vermutlich auch gar nicht wünschenswert.
Eine KI mit Bewusstsein wird ihre Aufgabe vermutlich nicht unbedingt besser machen, als eine KI ohne.
Sie könnte sogar Nachteile haben.
Einer KI mit Bewusstsein müsste wohl die selben Rechte haben wie ein Mensch, ist sich logischerweise auch ihrer Überlegenheit bewusst, wird also vermutlich schwerer zu kontrollieren sein.
Die Spekulationen, was so eine KI tun würde übernehmen genügend Filme.

\section{Quellen}
\begin{itemize}
\item \url{https://de.wikipedia.org/wiki/K%C3%BCnstliche_Intelligenz}
\item \url{https://de.wikipedia.org/wiki/Intelligenz}
\item \url{https://de.wikipedia.org/wiki/Bewusstsein}
\item \url{https://de.wikipedia.org/wiki/Wahrnehmung}
\item \url{https://de.wikipedia.org/wiki/Sensor}
\item \url{https://en.wikipedia.org/wiki/Computing_Machinery_and_Intelligence}
\item \url{https://de.wikipedia.org/wiki/AlphaGo}
\item \url{https://de.wikipedia.org/wiki/Deep_Blue}
\item \url{https://de.wikipedia.org/wiki/Turing-Test}
\item \url{https://de.wikipedia.org/wiki/Chinesisches_Zimmer}
\end{itemize}
